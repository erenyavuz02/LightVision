{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80b2c58",
   "metadata": {},
   "source": [
    "# Pull the LightVision repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99e46173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally - repository clone skipped\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    !git clone -b branch_name https://github.com/erenyavuz02/LightVision.git\n",
    "    print(\"Repository cloned in Google Colab\")\n",
    "except ImportError:\n",
    "    print(\"Running locally - repository clone skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd645c1",
   "metadata": {},
   "source": [
    "# Set the config manager to use the local config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "588adf44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n",
      "Project root: /Users/erenyavuz/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "try:\n",
    "    # Try to detect if running in Google Colab\n",
    "    import google.colab\n",
    "    # If running in Google Colab, you need to manually set the project root\n",
    "    # Update this path to match where you cloned/uploaded your project in Colab\n",
    "    project_root = '/content/LightVision'  # Adjust this path as needed for your Colab setup\n",
    "    print(\"Running in Google Colab\")\n",
    "except ImportError:\n",
    "    # Running locally\n",
    "    script_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "    project_root = os.path.abspath(os.path.join(script_dir, '.'))\n",
    "    print(\"Running locally\")\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Import ConfigManager\n",
    "from utils.config import ConfigManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5232990",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config_path = os.path.join(project_root, 'config', 'config.yaml')\n",
    "\n",
    "\n",
    "config = ConfigManager(config_path = config_path)\n",
    "\n",
    "# set the project root in the config project: \n",
    "config.update('project.root', project_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf2636",
   "metadata": {},
   "source": [
    "# Download the flickr dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "799fce8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting download process for Flickr8k...\n",
      "Dataset already exists: 8091 files found\n",
      "✅ Flickr8k Dataset: 8,091 images ready\n"
     ]
    }
   ],
   "source": [
    "# Download Flickr8k dataset\n",
    "from functions.dataset import DatasetDownloader\n",
    "from pathlib import Path\n",
    "\n",
    "datasetDownloader = DatasetDownloader(config)\n",
    "\n",
    "# Download dataset - removed extra config parameter\n",
    "if datasetDownloader.download_dataset(verbose=True):\n",
    "    # Verify dataset\n",
    "    images_dir = Path(config.get('project.root')) / 'data' / 'Images'\n",
    "    image_count = len(list(images_dir.glob('*.jpg')))\n",
    "    print(f\"✅ Flickr8k Dataset: {image_count:,} images ready\")\n",
    "else:\n",
    "    print(\"❌ Dataset download failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4935f081",
   "metadata": {},
   "source": [
    "# Download the base model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ce663e",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "print(\"📦 Installing required dependencies...\")\n",
    "!pip install -q open-clip-torch faiss-cpu transformers timm\n",
    "print(\"✅ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07cbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Base model already exists.\n",
      "🚀 Base model ready for training!\n"
     ]
    }
   ],
   "source": [
    "# Download base MobileCLIP model\n",
    "from functions.model import download_base_model\n",
    "\n",
    "if download_base_model(config, verbose=True):\n",
    "    print(\"🚀 Base model ready for training!\")\n",
    "else:\n",
    "    print(\"❌ Base model download failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd43cb",
   "metadata": {},
   "source": [
    "# Load the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cae271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💻 CUDA not available, using CPU\n",
      "Loading mobileclip_s0 model...\n",
      "Loading from checkpoint: /Users/erenyavuz/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/checkpoints/mobileclip_s0.pt\n",
      "✅ Model loaded successfully on cpu\n"
     ]
    }
   ],
   "source": [
    "from functions.model import load_model\n",
    "\n",
    "base_model, preprocess, tokenizer = load_model(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f00579",
   "metadata": {},
   "source": [
    "# Test Custom Dataset with Train/Test Split\n",
    "\n",
    "Test the CustomDataset class to ensure proper train/test splitting without data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effc926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset instance...\n"
     ]
    }
   ],
   "source": [
    "# Test CustomDataset class with single instance\n",
    "from functions.dataset import CustomDataset\n",
    "\n",
    "# Create a single dataset instance\n",
    "print(\"Creating dataset instance...\")\n",
    "dataset = CustomDataset(config, test_ratio=0.125, transform=preprocess)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57463a6e",
   "metadata": {},
   "source": [
    "# Evaluate the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b84fd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating base model performance...\n",
      "Starting dataset evaluation...\n",
      "Model: mobileclip_s0\n",
      "Device: cpu\n",
      "Dataset split: 5110 train, 730 test\n",
      "\n",
      "==================================================\n",
      "Evaluating train split\n",
      "==================================================\n",
      "Loaded index with 5110 vectors\n",
      "Using cached FAISS index\n",
      "Evaluating retrieval on train split...\n",
      "Processing 5110 queries...\n",
      "Processing query 1/5110\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating base model performance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Run evaluation\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m evaluation_results \u001b[38;5;241m=\u001b[39m evaluate_dataset(\n\u001b[1;32m      8\u001b[0m     model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[1;32m      9\u001b[0m     testDataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     10\u001b[0m     config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m     11\u001b[0m     k_values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m],  \u001b[38;5;66;03m# You can customize k values\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     force_rebuild_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,  \u001b[38;5;66;03m# Set to True to force rebuild FAISS index\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# The results will be automatically saved and printed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/functions/evaluate.py:164\u001b[0m, in \u001b[0;36mevaluate_dataset\u001b[0;34m(model, testDataset, config, k_values, force_rebuild_index, verbose)\u001b[0m\n\u001b[1;32m    161\u001b[0m     retriever\u001b[38;5;241m.\u001b[39mbuild_or_load_index(force_rebuild\u001b[38;5;241m=\u001b[39mforce_rebuild_index, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Evaluate retrieval performance\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     split_results \u001b[38;5;241m=\u001b[39m evaluate_retrieval(\n\u001b[1;32m    165\u001b[0m         retriever, testDataset, split\u001b[38;5;241m=\u001b[39msplit, \n\u001b[1;32m    166\u001b[0m         k_values\u001b[38;5;241m=\u001b[39mk_values, verbose\u001b[38;5;241m=\u001b[39mverbose\n\u001b[1;32m    167\u001b[0m     )\n\u001b[1;32m    169\u001b[0m     results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_results\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m split_results\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# Save results to file\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/functions/evaluate.py:57\u001b[0m, in \u001b[0;36mevaluate_retrieval\u001b[0;34m(retriever, dataset, split, k_values, verbose)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Test short captions\u001b[39;00m\n\u001b[1;32m     56\u001b[0m short_caption \u001b[38;5;241m=\u001b[39m item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshort_caption\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 57\u001b[0m short_results \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mretrieve(short_caption, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(k_values))\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Check if target image is in top-k for each k\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values:\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/functions/retriever.py:188\u001b[0m, in \u001b[0;36mFAISSRetriever.retrieve\u001b[0;34m(self, query_text, k, caption_type)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# Tokenize text (assuming mobileclip tokenizer)\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n\u001b[0;32m--> 188\u001b[0m     _, _, tokenizer \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    190\u001b[0m     text_tokens \u001b[38;5;241m=\u001b[39m tokenizer([query_text])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    191\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mencode_text(text_tokens)\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/functions/model.py:108\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(config, verbose)\u001b[0m\n\u001b[1;32m    105\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Get tokenizer\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m mobileclip\u001b[38;5;241m.\u001b[39mget_tokenizer(model_name)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Model loaded successfully on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/mobileclip/__init__.py:95\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m model_cfg \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(model_cfg_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Build tokenizer\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m text_tokenizer \u001b[38;5;241m=\u001b[39m ClipTokenizer(model_cfg)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_tokenizer\n",
      "File \u001b[0;32m~/Desktop/KU/25 Spring/COMP447/Project/Repo/FlightVision/mobileclip/modules/text/tokenizer.py:16\u001b[0m, in \u001b[0;36mClipTokenizer.__init__\u001b[0;34m(self, cfg, *args, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_length \u001b[38;5;241m=\u001b[39m cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_cfg\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopen_clip_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViT-B-16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m open_clip\u001b[38;5;241m.\u001b[39mget_tokenizer(model_name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/open_clip/factory.py:141\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[0;34m(model_name, context_length, cache_dir, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m SigLipTokenizer(\n\u001b[1;32m    136\u001b[0m         tn,\n\u001b[1;32m    137\u001b[0m         context_length\u001b[38;5;241m=\u001b[39mcontext_length,\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;66;03m# **tokenizer_kwargs,\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 141\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m SimpleTokenizer(\n\u001b[1;32m    142\u001b[0m         context_length\u001b[38;5;241m=\u001b[39mcontext_length,\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokenizer_kwargs,\n\u001b[1;32m    144\u001b[0m     )\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/open_clip/tokenizer.py:156\u001b[0m, in \u001b[0;36mSimpleTokenizer.__init__\u001b[0;34m(self, bpe_path, additional_special_tokens, context_length, clean, reduction_mask)\u001b[0m\n\u001b[1;32m    154\u001b[0m vocab\u001b[38;5;241m.\u001b[39mextend(special_tokens)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(vocab, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vocab))))\n\u001b[0;32m--> 156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m {v: k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbpe_ranks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(merges, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(merges))))\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m {t:t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m special_tokens}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functions.evaluate import evaluate_dataset\n",
    "\n",
    "# Evaluate the base model\n",
    "print(\"Evaluating base model performance...\")\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_dataset(\n",
    "    model=base_model,\n",
    "    testDataset=dataset,\n",
    "    config=config,\n",
    "    tokenizer=tokenizer,  # Pass the tokenizer here\n",
    "    k_values=[1, 5, 10, 20],  # You can customize k values\n",
    "    force_rebuild_index=False,  # Set to True to force rebuild FAISS index\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "\n",
    "# The results will be automatically saved and printed\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaea6348",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310c9333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cc92bab",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
